{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createa range of years and use pandas html scraping to create data frame of draft classes by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "draftYears = range(1999,2021)\n",
    "\n",
    "ColNames=['DraftYear', 'Rnd', 'Pick', 'Tm', 'Player', 'Pos', 'Age', 'To', 'AP1', 'PB', 'St', \n",
    " 'CarAV', 'DrAV', 'G', 'PassingCmp', 'PassingAtt', 'PassingYds', 'PassingTD', \n",
    " 'PassingInt', 'RushingAtt', 'RushingYds', 'RushingTD', 'ReceivingRec',\n",
    " 'ReceivingYds', 'ReceivingTD', 'ReceivingSolo', 'Int', 'Sk', 'College/Univ', \n",
    " 'CollegeStats'] \n",
    "\n",
    "draftDF = pd.DataFrame(columns = ColNames)\n",
    "\n",
    "\n",
    "for x in draftYears:\n",
    "    url = f'https://www.pro-football-reference.com/years/{x}/draft.htm'\n",
    "    dftLst = pd.read_html(url) # returns list\n",
    "    tempDF = pd.DataFrame(dftLst[0])\n",
    "    tempDF.insert(0, 'DraftYear', x)\n",
    "    tempDF.columns = ColNames\n",
    "    if x == min(draftYears):\n",
    "        draftDF = tempDF\n",
    "    else:\n",
    "        draftDF = draftDF.append(tempDF, ignore_index=True)\n",
    "    time.sleep(3)\n",
    "del tempDF\n",
    "   \n",
    "#Drop the College Stats column because it is just the text 'College Stats' - use bs to get the actual href and merge in subsequent steps\n",
    "draftDF.drop(['CollegeStats'], axis=1, inplace = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use soup to get the href on each row of the table\n",
    "# note - there are some players that do not have href for college stats so put in the try except\n",
    "cStatList = []\n",
    "\n",
    "for x in draftYears:\n",
    "    url = f'https://www.pro-football-reference.com/years/{x}/draft.htm'\n",
    "    \n",
    "    players = bs(requests.get(f'https://www.pro-football-reference.com/years/{x}/draft.htm').text, 'lxml')\\\n",
    "        .findAll('td', attrs={'data-stat':'player'})\n",
    "    \n",
    "    hrefs = bs(requests.get(f'https://www.pro-football-reference.com/years/{x}/draft.htm').text, 'lxml')\\\n",
    "        .findAll('td', attrs={'data-stat':'college_link'})\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        tdict ={}\n",
    "        try:\n",
    "            tdict['DraftYear'] = x\n",
    "            tdict['Player'] = players[i].text\n",
    "            tdict['CollegeStats'] = hrefs[i].a['href']\n",
    "\n",
    "        except:\n",
    "            tdict['DraftYear'] = x\n",
    "            tdict['Player'] = players[i].text\n",
    "            tdict['CollegeStats'] = ''\n",
    "\n",
    "        cStatList.append(tdict)\n",
    "\n",
    "        i+=1\n",
    "        if(i > len(players)-1):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a datafrom fome the list that was created\n",
    "statLinkDF = pd.DataFrame(cStatList)\n",
    "#StatLinkDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the data with the draftDF dataframe (use an inner join- will take care of a flaw in the first df)\n",
    "draftScrapeDF = pd.merge(left=draftDF, right=statLinkDF, left_on=['DraftYear','Player'], right_on=['DraftYear','Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit to sqlite database\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect\n",
    "engine = create_engine('sqlite:///../data/fbdata.sqlite')\n",
    "draftScrapeDF.to_sql('draftHistory', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
